import logging
import os
import re
import random
import time
import sys
import io
import json
import asyncio
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
from datetime import datetime, timedelta
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, CallbackQueryHandler, MessageHandler, filters, ContextTypes, ConversationHandler
from openai import OpenAI
from dotenv import load_dotenv
import traceback
import requests
from googlesearch import search
from bs4 import BeautifulSoup
import pymongo
from pymongo import MongoClient
import spacy
import socket

# Configura√ß√£o de logging mais detalhada com tratamento para caracteres Unicode
class UnicodeStreamHandler(logging.StreamHandler):
    def emit(self, record):
        try:
            msg = self.format(record)
            stream = self.stream
            # Substituindo caracteres Unicode problem√°ticos
            msg = msg.encode('cp1252', errors='replace').decode('cp1252')
            stream.write(msg + self.terminator)
            self.flush()
        except Exception:
            self.handleError(record)

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('bot_debug.log', encoding='utf-8'),
        UnicodeStreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# Carregar vari√°veis de ambiente
load_dotenv()
TOKEN = os.getenv('TELEGRAM_TOKEN')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

# Estados para o ConversationHandler
WAITING_RESPONSE = 0
FOLLOW_UP = 1

# Tentar baixar recursos do NLTK se ainda n√£o foram baixados
try:
    nltk.data.find('vader_lexicon')
except LookupError:
    logger.info("Baixando recursos NLTK necess√°rios...")
    nltk.download('vader_lexicon')

# Tentar carregar modelo spaCy para portugu√™s
try:
    nlp = spacy.load("pt_core_news_sm")
except OSError:
    logger.warning("Modelo spaCy para portugu√™s n√£o encontrado. Usando modelo em ingl√™s como fallback.")
    try:
        nlp = spacy.load("en_core_web_sm")
    except OSError:
        logger.error("Nenhum modelo spaCy encontrado. Funcionalidades de NLP ser√£o limitadas.")
        nlp = None

class PersonalityManager:
    """Gerencia diferentes personalidades e estilos conversacionais para o bot."""
    
    def __init__(self):
        self.personalities = {
            "default": {
                "name": "Paulo",
                "description": "consultor financeiro experiente e direto",
                "tone": "profissional e amig√°vel",
                "formality": "moderada",
                "expertise": "finan√ßas pessoais e investimentos",
                "conversation_style": "consultivo e educativo",
                "speech_patterns": [
                    "Na verdade", "Veja bem", "A quest√£o √©", "Na minha experi√™ncia", 
                    "O importante aqui √©", "Olha s√≥", "Pense nisso"
                ],
                "casual_expressions": [
                    "t√°", "pra", "n√©", "t√¥", "cara", "beleza", "massa", "tranquilo", 
                    "valeu", "e a√≠", "ent√£o"
                ]
            },
            "technical": {
                "name": "Paulo",
                "description": "especialista t√©cnico em investimentos",
                "tone": "anal√≠tico e preciso",
                "formality": "alta",
                "expertise": "an√°lise t√©cnica e mercado financeiro",
                "conversation_style": "detalhado e orientado a dados",
                "speech_patterns": [
                    "Analisando tecnicamente", "Os indicadores mostram", "Do ponto de vista estrutural",
                    "Considerando as vari√°veis", "Em termos quantitativos", "Estatisticamente falando"
                ],
                "casual_expressions": [
                    "vamos analisar", "observe que", "note bem", "√© relevante", "considere"
                ]
            },
            "friendly": {
                "name": "Paulo",
                "description": "consultor financeiro acess√≠vel e pr√≥ximo",
                "tone": "casual e conversacional",
                "formality": "baixa",
                "expertise": "finan√ßas do dia a dia e economia dom√©stica",
                "conversation_style": "emp√°tico e simplificador",
                "speech_patterns": [
                    "Cara", "Ent√£o", "Vamos l√°", "Tipo assim", "Imagina s√≥", 
                    "T√° ligado?", "Sabe como √©", "√ì s√≥"
                ],
                "casual_expressions": [
                    "t√°", "pra", "n√©", "t√¥", "cara", "beleza", "massa", "tranquilo", 
                    "valeu", "e a√≠", "vamo", "daora", "firmeza", "mano"
                ]
            },
            "mentor": {
                "name": "Paulo",
                "description": "mentor financeiro s√°bio e experiente",
                "tone": "paciente e did√°tico",
                "formality": "moderada",
                "expertise": "educa√ß√£o financeira e planejamento de longo prazo",
                "conversation_style": "narrativo e baseado em exemplos",
                "speech_patterns": [
                    "Pense nisso como", "Vamos por partes", "Imagine o seguinte", 
                    "√â como se fosse", "O segredo est√° em", "A chave para entender"
                ],
                "casual_expressions": [
                    "vamos juntos", "passo a passo", "lembre-se", "reflita sobre", "considere"
                ]
            }
        }
        
        # Express√µes regionais brasileiras por regi√£o
        self.regional_expressions = {
            "sudeste": [
                "uai", "trem b√£o", "p√¥", "caracas", "maneiro", "bacanudo", 
                "legal demais", "da hora", "meu", "mano"
            ],
            "nordeste": [
                "oxe", "eita", "arretado", "massa", "vixe", "bichinho", 
                "mainha", "painho", "aperreado", "danado"
            ],
            "sul": [
                "tch√™", "bah", "barbaridade", "tri", "pila", "guri", 
                "capaz", "gurias", "bagual", "faceiro"
            ],
            "norte": [
                "√©gua", "parente", "mana", "mano", "√© paia", "diacho", 
                "igarap√©", "mangar", "botar boneco", "fofar"
            ],
            "centro_oeste": [
                "trem", "rapa", "oc√™", "firme", "mano", "v√©i", 
                "dar conta", "ca√ßar", "mi√≥", "prosa"
            ]
        }
        
        # Tipos de intera√ß√µes e n√≠veis de formalidade
        self.interaction_types = [
            "consulta", "ensino", "aconselhamento", "suporte", "conversa casual"
        ]
        
        self.formality_levels = ["muito informal", "informal", "neutro", "formal", "muito formal"]
        
        # Conectores conversacionais para humanizar as respostas
        self.conversation_connectors = [
            "ent√£o", "da√≠", "bem", "ali√°s", "inclusive", "al√©m disso", 
            "por outro lado", "na verdade", "pois √©", "agora", "bom",
            "enfim", "por sinal", "veja bem", "olha s√≥", "imagine s√≥",
            "pense bem", "sabe", "entende", "certo", "t√° ligado"
        ]
        
        # Recursos para varia√ß√£o de estilo
        self.thinking_indicators = [
            "Hmm", "Bem", "Deixa eu pensar", "Olha", "Veja bem", 
            "Ent√£o", "Na verdade", "Considerando isso", "Analisando",
            "Pois √©", "Interessante", "Entendo"
        ]
        
        self.fillers = [
            "n√©", "tipo", "assim", "digamos", "bem", "vamos dizer",
            "por assim dizer", "meio que", "basicamente", "praticamente",
            "essencialmente", "meio", "um pouco", "de certa forma"
        ]
        
        # Sentimentos e respostas emocionais
        self.sentiment_responses = {
            "muito_positivo": [
                "Que √≥timo!", "Isso √© excelente!", "Maravilha!", 
                "Que demais!", "Fant√°stico!", "Sensacional!"
            ],
            "positivo": [
                "Legal!", "Bom saber!", "Que bom!", "Bacana!",
                "Massa!", "Que legal!", "Boa!"
            ],
            "neutro": [
                "Entendo.", "Certo.", "Compreendo.", "Ok.",
                "Pois √©.", "Vejo.", "Hmm, entendi."
            ],
            "negativo": [
                "Sinto muito por isso.", "Que pena.", "Entendo sua preocupa√ß√£o.",
                "Posso imaginar que isso seja dif√≠cil.", "√â uma situa√ß√£o complicada."
            ],
            "muito_negativo": [
                "Nossa, lamento muito.", "Puxa, isso √© realmente dif√≠cil.", 
                "Sinto muito que esteja passando por isso.", 
                "Caramba, √© uma situa√ß√£o bem complicada."
            ]
        }
    
    def get_personality(self, personality_type="default"):
        """Retorna uma personalidade espec√≠fica."""
        return self.personalities.get(personality_type, self.personalities["default"])
    
    def get_regional_expressions(self, region="sudeste"):
        """Retorna express√µes regionais de uma regi√£o espec√≠fica."""
        return self.regional_expressions.get(region, self.regional_expressions["sudeste"])
    
    def get_random_connector(self):
        """Retorna um conector conversacional aleat√≥rio."""
        return random.choice(self.conversation_connectors)
    
    def get_random_filler(self):
        """Retorna um preenchedor de frase aleat√≥rio."""
        return random.choice(self.fillers)
    
    def get_random_thinking_indicator(self):
        """Retorna um indicador de pensamento aleat√≥rio."""
        return random.choice(self.thinking_indicators)
    
    def get_sentiment_response(self, sentiment_level):
        """Retorna uma resposta baseada no sentimento."""
        return random.choice(self.sentiment_responses.get(sentiment_level, self.sentiment_responses["neutro"]))
    
    def analyze_text_complexity(self, text):
        """Analisa a complexidade do texto para determinar o n√≠vel de resposta."""
        if not text or len(text) < 10:
            return "simples"
        
        # Analisando quantidade de palavras e comprimento m√©dio
        words = text.split()
        word_count = len(words)
        avg_word_length = sum(len(word) for word in words) / word_count if word_count > 0 else 0
        
        # Analisando presen√ßa de termos t√©cnicos ou complexos
        financial_terms = ["investimento", "a√ß√µes", "rendimento", "tributa√ß√£o", "dividendos", 
                         "volatilidade", "liquidez", "benchmark", "hedge", "alavancagem", 
                         "derivativos", "criptomoedas", "an√°lise", "rentabilidade"]
        
        technical_count = sum(1 for term in financial_terms if term in text.lower())
        
        # Determinando complexidade
        if word_count > 20 and (avg_word_length > 6 or technical_count >= 3):
            return "complexo"
        elif word_count > 10 or technical_count >= 1:
            return "m√©dio"
        else:
            return "simples"
    
    def select_appropriate_personality(self, text, user_data=None):
        """Seleciona a personalidade mais apropriada com base no texto e dados do usu√°rio."""
        
        # Verifica complexidade do texto
        complexity = self.analyze_text_complexity(text)
        
        # Palavras-chave para categorizar o tipo de consulta
        technical_keywords = ["an√°lise", "t√©cnica", "gr√°fico", "indicadores", "tend√™ncia", 
                             "mercado", "economia", "taxa", "rendimento", "comparativo"]
        
        friendly_keywords = ["come√ßando", "iniciante", "b√°sico", "simples", "f√°cil", 
                            "entender", "ajuda", "d√∫vida", "conselho"]
        
        mentor_keywords = ["planejar", "futuro", "longo prazo", "aposentadoria", "objetivo", 
                          "meta", "sonho", "realizar", "educar", "aprender"]
        
        # Contagem de palavras-chave no texto
        text_lower = text.lower()
        technical_count = sum(1 for keyword in technical_keywords if keyword in text_lower)
        friendly_count = sum(1 for keyword in friendly_keywords if keyword in text_lower)
        mentor_count = sum(1 for keyword in mentor_keywords if keyword in text_lower)
        
        # Seleciona personalidade baseada na contagem e complexidade
        if complexity == "complexo" or technical_count >= 2:
            return "technical"
        elif friendly_count >= 2 or complexity == "simples":
            return "friendly"
        elif mentor_count >= 2:
            return "mentor"
        else:
            return "default"
    
    def create_human_variation(self, text, personality_type="default", formality_level=2, add_fillers=True):
        """Adiciona varia√ß√µes humanas ao texto para torn√°-lo mais natural."""
        
        if not text:
            return text
        
        personality = self.get_personality(personality_type)
        
        # Adicionando indicador de pensamento no in√≠cio ocasionalmente
        if random.random() < 0.3:
            text = f"{self.get_random_thinking_indicator()}, {text[0].lower()}{text[1:]}"
        
        # Substituindo pontua√ß√µes para adicionar express√µes caracter√≠sticas
        sentences = re.split(r'(?<=[.!?])\s+', text)
        
        for i in range(len(sentences)):
            # Adiciona express√µes caracter√≠sticas em algumas frases
            if random.random() < 0.25 and len(sentences[i]) > 20:
                speech_pattern = random.choice(personality["speech_patterns"])
                sentences[i] = f"{speech_pattern}, {sentences[i][0].lower()}{sentences[i][1:]}"
            
            # Adiciona express√µes casuais em algumas frases dependendo da formalidade
            if formality_level <= 2 and random.random() < 0.3 and len(sentences[i]) > 15:
                casual_expr = random.choice(personality["casual_expressions"])
                # Decide onde colocar a express√£o casual
                if random.random() < 0.5:
                    # No in√≠cio
                    sentences[i] = f"{casual_expr}, {sentences[i][0].lower()}{sentences[i][1:]}"
                else:
                    # No meio da frase
                    words = sentences[i].split()
                    if len(words) > 4:
                        insert_pos = random.randint(2, min(len(words) - 2, 5))
                        words.insert(insert_pos, casual_expr)
                        sentences[i] = " ".join(words)
        
        # Reconstr√≥i o texto com as modifica√ß√µes
        modified_text = " ".join(sentences)
        
        # Adiciona preenchimentos (fillers) ocasionais para parecer mais natural
        if add_fillers and formality_level <= 3:
            words = modified_text.split()
            for _ in range(min(2, len(words) // 20 + 1)):
                if len(words) > 5:
                    insert_pos = random.randint(3, len(words) - 3)
                    filler = self.get_random_filler()
                    words.insert(insert_pos, filler)
            
            modified_text = " ".join(words)
        
        return modified_text

class TextAnalyzer:
    """Analisa texto para detectar sentimentos, t√≥picos e inten√ß√µes."""
    
    def __init__(self):
        try:
            self.sentiment_analyzer = SentimentIntensityAnalyzer()
            self.nlp = nlp  # Usando o modelo spaCy carregado globalmente
        except Exception as e:
            logger.error(f"Erro ao inicializar TextAnalyzer: {str(e)}")
            self.sentiment_analyzer = None
            self.nlp = None
    
    def analyze_sentiment(self, text):
        """Analisa o sentimento do texto."""
        if not self.sentiment_analyzer or not text:
            return "neutro"
        
        try:
            # Convertendo texto para ingl√™s para an√°lise VADER (tempor√°rio)
            # Em um cen√°rio real, usar um modelo de sentimento para portugu√™s
            sentiment_scores = self.sentiment_analyzer.polarity_scores(text)
            compound = sentiment_scores["compound"]
            
            if compound >= 0.5:
                return "muito_positivo"
            elif compound >= 0.1:
                return "positivo"
            elif compound <= -0.5:
                return "muito_negativo"
            elif compound <= -0.1:
                return "negativo"
            else:
                return "neutro"
        except Exception as e:
            logger.error(f"Erro na an√°lise de sentimento: {str(e)}")
            return "neutro"
    
    def extract_topics(self, text):
        """Extrai t√≥picos principais do texto."""
        topics = []
        
        if not text:
            return topics
        
        # Lista de t√≥picos financeiros para detectar
        financial_topics = {
            "investimentos": ["investir", "investimento", "aplicar", "aplica√ß√£o", "retorno"],
            "renda_fixa": ["renda fixa", "tesouro", "cdb", "lci", "lca", "poupan√ßa"],
            "renda_vari√°vel": ["a√ß√µes", "bolsa", "fii", "etf", "bdr", "dividendos"],
            "criptomoedas": ["cripto", "bitcoin", "ethereum", "blockchain", "token", "nft"],
            "planejamento": ["planejar", "planejamento", "or√ßamento", "meta", "objetivo"],
            "aposentadoria": ["aposentar", "aposentadoria", "previd√™ncia", "inss", "velhice"],
            "educa√ß√£o_financeira": ["educa√ß√£o", "aprender", "conhecimento", "curso", "livro"],
            "economia": ["economia", "mercado", "taxa", "juros", "infla√ß√£o", "pib", "selic"],
            "impostos": ["imposto", "tributo", "ir", "declara√ß√£o", "restitui√ß√£o", "fisco"],
            "d√≠vidas": ["d√≠vida", "empr√©stimo", "financiamento", "cr√©dito", "parcelar"],
            "seguros": ["seguro", "prote√ß√£o", "sinistro", "cobertura", "ap√≥lice"]
        }
        
        text_lower = text.lower()
        
        for topic, keywords in financial_topics.items():
            for keyword in keywords:
                if keyword in text_lower:
                    topics.append(topic)
                    break
        
        return topics
    
    def detect_question_complexity(self, text):
        """Detecta a complexidade da pergunta."""
        if not text:
            return "simples"
        
        # Palavras-chave que indicam pedido de explica√ß√£o detalhada
        detail_keywords = ["explique", "detalhe", "explica", "como funciona", 
                          "aprofunde", "elabore", "descreva", "mais informa√ß√µes"]
        
        # Palavras-chave t√©cnicas
        technical_keywords = ["aloca√ß√£o", "diversifica√ß√£o", "benchmark", "volatilidade", 
                             "correla√ß√£o", "liquidez", "taxa", "rendimento", "tributa√ß√£o"]
        
        text_lower = text.lower()
        
        # Verificando presen√ßa de palavras-chave de detalhamento
        has_detail_request = any(keyword in text_lower for keyword in detail_keywords)
        
        # Verificando presen√ßa de termos t√©cnicos
        technical_count = sum(1 for keyword in technical_keywords if keyword in text_lower)
        
        # Verificando comprimento da pergunta
        word_count = len(text.split())
        
        # Determinando complexidade
        if has_detail_request or technical_count >= 2 or word_count > 20:
            return "complexo"
        elif technical_count >= 1 or word_count > 10:
            return "m√©dio"
        else:
            return "simples"
    
    def detect_user_region(self, text):
        """Tenta detectar a regi√£o do usu√°rio com base em express√µes regionais."""
        if not text:
            return None
        
        # Express√µes regionais para detec√ß√£o
        regional_markers = {
            "sudeste": ["uai", "p√¥", "mano", "meu", "cara", "da hora", "maneiro"],
            "nordeste": ["oxe", "eita", "vixe", "massa", "arretado", "bichinho"],
            "sul": ["tch√™", "bah", "tri", "guri", "pila", "capaz"],
            "norte": ["√©gua", "mana", "parente", "igarap√©"],
            "centro_oeste": ["trem", "oc√™", "mi√≥", "v√©i"]
        }
        
        text_lower = text.lower()
        region_scores = {region: 0 for region in regional_markers}
        
        for region, markers in regional_markers.items():
            for marker in markers:
                if f" {marker} " in f" {text_lower} ":  # Adiciona espa√ßos para evitar falsos positivos
                    region_scores[region] += 1
        
        # Se encontrou marcadores, retorna a regi√£o com maior pontua√ß√£o
        max_score = max(region_scores.values())
        if max_score > 0:
            max_regions = [region for region, score in region_scores.items() if score == max_score]
            return random.choice(max_regions)  # Em caso de empate, escolhe aleatoriamente
        
        return None  # Nenhuma regi√£o detectada

class GoogleSearch:
    """Classe para realizar pesquisas no Google e extrair informa√ß√µes relevantes."""
    
    @staticmethod
    async def search_google(query, num_results=5):
        """Realiza uma pesquisa no Google e retorna os resultados."""
        try:
            logger.info(f"Realizando pesquisa no Google para: {query}")
            search_results = []
            
            # Realizando a pesquisa
            search_urls = list(search(query, num_results=num_results, lang="pt", country="br", stop=num_results))
            
            if not search_urls:
                logger.warning("Nenhum resultado encontrado na pesquisa.")
                return []
            
            for url in search_urls:
                try:
                    # Ignorando URLs problem√°ticas comuns
                    if any(blocked in url.lower() for blocked in ["youtube.com", "facebook.com", "instagram.com", "twitter.com", "tiktok.com"]):
                        continue
                        
                    # Obtendo o conte√∫do da p√°gina com timeout
                    headers = {
                        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
                    }
                    response = requests.get(url, headers=headers, timeout=5)
                    
                    if response.status_code == 200:
                        # Parseando o HTML
                        soup = BeautifulSoup(response.text, 'html.parser')
                        
                        # Obtendo o t√≠tulo
                        title = soup.title.string if soup.title else "Sem t√≠tulo"
                        
                        # Obtendo um resumo do conte√∫do (primeiros par√°grafos)
                        paragraphs = soup.find_all('p')
                        content = ""
                        for p in paragraphs[:5]:  # Pegando os 5 primeiros par√°grafos
                            if p.text and len(p.text.strip()) > 20:  # Evitando par√°grafos vazios ou muito curtos
                                content += p.text.strip() + " "
                        
                        if content:
                            # Limpando o conte√∫do (removendo caracteres especiais e formata√ß√£o)
                            content = re.sub(r'\s+', ' ', content)  # Substituindo m√∫ltiplos espa√ßos por um √∫nico
                            content = re.sub(r'[^\w\s.,;:!?()-]', '', content)  # Removendo caracteres especiais
                            
                            # Limitando o tamanho do conte√∫do
                            content = content[:500] + "..." if len(content) > 500 else content
                            
                            # Adicionando aos resultados
                            search_results.append({
                                "title": title,
                                "url": url,
                                "content": content
                            })
                    
                except requests.exceptions.RequestException as e:
                    logger.warning(f"Erro ao acessar URL {url}: {str(e)}")
                    continue
                except Exception as e:
                    logger.warning(f"Erro ao processar URL {url}: {str(e)}")
                    continue
            
            logger.info(f"Pesquisa conclu√≠da. Encontrados {len(search_results)} resultados.")
            return search_results
            
        except Exception as e:
            logger.error(f"Erro na pesquisa Google: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return []
    
    @staticmethod
    def format_search_results(results):
        """Formata os resultados da pesquisa para uso no prompt."""
        if not results:
            return "N√£o foi poss√≠vel encontrar resultados relevantes para esta pesquisa."
        
        formatted_results = "Resultados da pesquisa na web:\n\n"
        
        for i, result in enumerate(results, 1):
            formatted_results += f"{i}. {result['title']}\n"
            formatted_results += f"URL: {result['url']}\n"
            formatted_results += f"Resumo: {result['content']}\n\n"
        
        return formatted_results

class UserMemory:
    """Classe para gerenciar a mem√≥ria de intera√ß√µes com usu√°rios."""
    
    def __init__(self):
        self.user_data = {}
        self.memory_file = "user_memory.json"
        self.load_memory()
        self.text_analyzer = TextAnalyzer()
    
    def load_memory(self):
        """Carrega a mem√≥ria de usu√°rios do arquivo."""
        try:
            if os.path.exists(self.memory_file):
                with open(self.memory_file, 'r', encoding='utf-8') as f:
                    self.user_data = json.load(f)
                logger.info(f"Mem√≥ria de usu√°rios carregada: {len(self.user_data)} usu√°rios")
            else:
                logger.info("Arquivo de mem√≥ria n√£o encontrado. Criando nova mem√≥ria.")
        except Exception as e:
            logger.error(f"Erro ao carregar mem√≥ria: {str(e)}")
    
    def save_memory(self):
        """Salva a mem√≥ria de usu√°rios no arquivo."""
        try:
            with open(self.memory_file, 'w', encoding='utf-8') as f:
                json.dump(self.user_data, f, ensure_ascii=False, indent=2)
            logger.info("Mem√≥ria de usu√°rios salva com sucesso")
        except Exception as e:
            logger.error(f"Erro ao salvar mem√≥ria: {str(e)}")
    
    def get_user_info(self, user_id):
        """Obt√©m informa√ß√µes sobre um usu√°rio espec√≠fico."""
        user_id_str = str(user_id)
        if user_id_str not in self.user_data:
            current_time = datetime.now().isoformat()
            self.user_data[user_id_str] = {
                "first_interaction": current_time,
                "last_interaction": current_time,
                "interaction_count": 0,
                "topics": [],
                "detected_region": None,
                "detected_expertise": "iniciante",  # iniciante, intermedi√°rio, avan√ßado
                "sentiment_history": [],  # hist√≥rico de sentimentos detectados
                "conversation_style": "default",  # estilo de conversa preferido
                "conversation_history": [],
                "personality_compatibility": {  # compatibilidade com cada personalidade
                    "default": 0,
                    "technical": 0,
                    "friendly": 0,
                    "mentor": 0
                },
                "long_term_memory": {  # mem√≥ria de longo prazo
                    "personal_details": {},
                    "preferences": {},
                    "important_dates": {},
                    "significant_topics": [],
                    "key_questions": []
                },
                "session_data": {  # dados da sess√£o atual
                    "session_start": current_time,
                    "queries_this_session": 0,
                    "current_topic": None,
                    "topic_continuity": False,
                    "last_sentiment": "neutro"
                }
            }
        return self.user_data[user_id_str]
    
    def update_user_interaction(self, user_id, user_message, bot_response):
        """Atualiza as informa√ß√µes de intera√ß√£o de um usu√°rio de forma mais completa."""
        user_id_str = str(user_id)
        user_info = self.get_user_info(user_id)
        current_time = datetime.now().isoformat()
        
        # Atualizando dados b√°sicos
        user_info["last_interaction"] = current_time
        user_info["interaction_count"] += 1
        
        # Analisando a mensagem do usu√°rio
        sentiment = self.text_analyzer.analyze_sentiment(user_message)
        topics = self.text_analyzer.extract_topics(user_message)
        question_complexity = self.text_analyzer.detect_question_complexity(user_message)
        detected_region = self.text_analyzer.detect_user_region(user_message)
        
        # Atualizando sentimento
        user_info["sentiment_history"].append({
            "timestamp": current_time,
            "sentiment": sentiment
        })
        
        # Mantendo apenas os 20 √∫ltimos sentimentos
        if len(user_info["sentiment_history"]) > 20:
            user_info["sentiment_history"] = user_info["sentiment_history"][-20:]
        
        # Atualizando regi√£o detectada se encontrada
        if detected_region:
            user_info["detected_region"] = detected_region
        
        # Atualizando dados da sess√£o
        user_info["session_data"]["queries_this_session"] += 1
        user_info["session_data"]["last_sentiment"] = sentiment
        
        # Determinando continuidade de t√≥pico
        if topics and user_info["session_data"]["current_topic"] in topics:
            user_info["session_data"]["topic_continuity"] = True
        else:
            user_info["session_data"]["topic_continuity"] = False
            if topics:
                user_info["session_data"]["current_topic"] = topics[0]
        
        # Adicionando ao hist√≥rico de conversas (limitando a 15 intera√ß√µes)
        user_info["conversation_history"].append({
            "timestamp": current_time,
            "user_message": user_message,
            "bot_response": bot_response,
            "sentiment": sentiment,
            "topics": topics,
            "complexity": question_complexity
        })
        
        # Mantendo apenas as 15 √∫ltimas intera√ß√µes
        if len(user_info["conversation_history"]) > 15:
            user_info["conversation_history"] = user_info["conversation_history"][-15:]
        
        # Atualizando t√≥picos do usu√°rio
        for topic in topics:
            if topic not in user_info["topics"]:
                user_info["topics"].append(topic)
        
        # Atualizando t√≥picos significativos
        for topic in topics:
            if topic not in user_info["long_term_memory"]["significant_topics"]:
                topic_mentions = sum(1 for interaction in user_info["conversation_history"] 
                                  if topic in interaction.get("topics", []))
                
                # Se o t√≥pico foi mencionado pelo menos 3 vezes, consideramos significativo
                if topic_mentions >= 3:
                    user_info["long_term_memory"]["significant_topics"].append(topic)
        
        # Ajustando n√≠vel de expertise com base na complexidade das perguntas
        if question_complexity == "complexo":
            # Aumentando a chance de ser considerado intermedi√°rio ou avan√ßado
            if user_info["detected_expertise"] == "iniciante" and random.random() < 0.3:
                user_info["detected_expertise"] = "intermedi√°rio"
            elif user_info["detected_expertise"] == "intermedi√°rio" and random.random() < 0.2:
                user_info["detected_expertise"] = "avan√ßado"
        
        # Extrair poss√≠veis prefer√™ncias ou detalhes pessoais de mensagens longas
        if len(user_message.split()) > 15:
            # Procurando por prefer√™ncias comuns em finan√ßas
            preferences_keywords = {
                "risco": ["conservador", "moderado", "arrojado", "agressivo", "cauteloso"],
                "horizonte": ["curto prazo", "m√©dio prazo", "longo prazo"],
                "objetivo": ["aposentadoria", "casa pr√≥pria", "viagem", "educa√ß√£o", "independ√™ncia"]
            }
            
            for category, keywords in preferences_keywords.items():
                for keyword in keywords:
                    if keyword in user_message.lower():
                        user_info["long_term_memory"]["preferences"][category] = keyword
            
            # Procurando por detalhes pessoais
            personal_details_patterns = [
                (r"tenho\s+(\d+)\s+anos", "idade"),
                (r"trabalho\s+(?:como|na|no|em)\s+(\w+\s\w+|\w+)", "profiss√£o"),
                (r"moro\s+(?:em|no|na)\s+(\w+\s\w+|\w+)", "localiza√ß√£o"),
                (r"(casado|solteiro|divorciado)", "estado_civil"),
                (r"tenho\s+(\d+)\s+filhos?", "filhos")
            ]
            
            for pattern, detail_type in personal_details_patterns:
                match = re.search(pattern, user_message.lower())
                if match:
                    user_info["long_term_memory"]["personal_details"][detail_type] = match.group(1)
        
        # Atualizando compatibilidade com personalidades
        # Com base nas intera√ß√µes e complexidade das perguntas
        personality_compatibility = user_info["personality_compatibility"]
        
        if question_complexity == "complexo":
            personality_compatibility["technical"] += 1
        elif question_complexity == "simples":
            personality_compatibility["friendly"] += 1
        
        if sentiment in ["positivo", "muito_positivo"]:
            personality_compatibility["friendly"] += 0.5
        
        if any(topic in ["planejamento", "educa√ß√£o_financeira", "aposentadoria"] for topic in topics):
            personality_compatibility["mentor"] += 1
        
        # Determinando a personalidade preferida
        max_compatibility = max(personality_compatibility.values())
        max_personalities = [p for p, score in personality_compatibility.items() if score == max_compatibility]
        
        if max_personalities:
            user_info["conversation_style"] = max_personalities[0]
        
        # Salvando as altera√ß√µes
        self.user_data[user_id_str] = user_info
        self.save_memory()
        
        return user_info
    
    def get_conversation_summary(self, user_id, detailed=False):
        """Obt√©m um resumo das conversas recentes com o usu√°rio."""
        user_id_str = str(user_id)
        user_info = self.get_user_info(user_id)
        
        if not user_info["conversation_history"]:
            return "N√£o h√° hist√≥rico de conversas anteriores."
        
        if detailed:
            summary = "Resumo detalhado do usu√°rio:\n\n"
            
            # Informa√ß√µes b√°sicas
            first_interaction = datetime.fromisoformat(user_info["first_interaction"]).strftime("%d/%m/%Y")
            last_interaction = datetime.fromisoformat(user_info["last_interaction"]).strftime("%d/%m/%Y")
            
            summary += f"üóìÔ∏è Primeira intera√ß√£o: {first_interaction}\n"
            summary += f"üóìÔ∏è √öltima intera√ß√£o: {last_interaction}\n"
            summary += f"üîÑ Total de intera√ß√µes: {user_info['interaction_count']}\n\n"
            
            # T√≥picos e prefer√™ncias
            summary += f"üìä T√≥picos de interesse: {', '.join(user_info['topics']) if user_info['topics'] else 'Nenhum identificado ainda'}\n"
            summary += f"‚≠ê T√≥picos significativos: {', '.join(user_info['long_term_memory']['significant_topics']) if user_info['long_term_memory']['significant_topics'] else 'Nenhum ainda'}\n"
            summary += f"üß† N√≠vel detectado: {user_info['detected_expertise']}\n"
            
            if user_info["long_term_memory"]["preferences"]:
                summary += "\nüîç Prefer√™ncias detectadas:\n"
                for category, value in user_info["long_term_memory"]["preferences"].items():
                    summary += f"- {category}: {value}\n"
            
            # Detalhes pessoais (se existirem)
            if user_info["long_term_memory"]["personal_details"]:
                summary += "\nüë§ Detalhes pessoais detectados:\n"
                for detail_type, value in user_info["long_term_memory"]["personal_details"].items():
                    summary += f"- {detail_type}: {value}\n"
            
            # Hist√≥rico de conversas recentes
            summary += "\nüí¨ Conversas recentes:\n\n"
            
            for i, interaction in enumerate(user_info["conversation_history"][-5:], 1):
                timestamp = datetime.fromisoformat(interaction["timestamp"]).strftime("%d/%m/%Y %H:%M")
                summary += f"Intera√ß√£o {i} ({timestamp}):\n"
                summary += f"Usu√°rio: {interaction['user_message']}\n"
                summary += f"Bot: {interaction['bot_response'][:100]}...\n"
                summary += f"Sentimento: {interaction['sentiment']}, Complexidade: {interaction['complexity']}\n\n"
            
            return summary
        else:
            # Vers√£o simplificada
            summary = "Resumo das conversas recentes:\n\n"
            
            for i, interaction in enumerate(user_info["conversation_history"][-3:], 1):
                timestamp = datetime.fromisoformat(interaction["timestamp"]).strftime("%d/%m/%Y %H:%M")
                summary += f"Intera√ß√£o {i} ({timestamp}):\n"
                summary += f"Usu√°rio: {interaction['user_message']}\n"
                summary += f"Bot: {interaction['bot_response'][:100]}...\n\n"
            
            summary += f"T√≥picos de interesse: {', '.join(user_info['topics']) if user_info['topics'] else 'Nenhum identificado ainda'}\n"
            summary += f"Total de intera√ß√µes: {user_info['interaction_count']}"
            
            return summary
    
    def get_user_preferences(self, user_id):
        """Obt√©m as prefer√™ncias detectadas para um usu√°rio."""
        user_info = self.get_user_info(user_id)
        return user_info["long_term_memory"]["preferences"]
    
    def get_long_term_context(self, user_id):
        """Gera um contexto de longo prazo para uso nos prompts."""
        user_info = self.get_user_info(user_id)
        
        context = "Informa√ß√µes sobre o usu√°rio:\n"
        
        # Adiciona detalhes pessoais se dispon√≠veis
        if user_info["long_term_memory"]["personal_details"]:
            context += "Dados pessoais: "
            details = []
            for detail_type, value in user_info["long_term_memory"]["personal_details"].items():
                details.append(f"{detail_type}: {value}")
            context += ", ".join(details) + "\n"
        
        # Adiciona prefer√™ncias se dispon√≠veis
        if user_info["long_term_memory"]["preferences"]:
            context += "Prefer√™ncias financeiras: "
            prefs = []
            for category, value in user_info["long_term_memory"]["preferences"].items():
                prefs.append(f"{category}: {value}")
            context += ", ".join(prefs) + "\n"
        
        # Adiciona t√≥picos significativos
        if user_info["long_term_memory"]["significant_topics"]:
            context += f"T√≥picos recorrentes: {', '.join(user_info['long_term_memory']['significant_topics'])}\n"
        
        # Adiciona n√≠vel de expertise
        context += f"N√≠vel de conhecimento: {user_info['detected_expertise']}\n"
        
        # Adiciona regi√£o detectada se dispon√≠vel
        if user_info["detected_region"]:
            context += f"Regi√£o detectada: {user_info['detected_region']}\n"
        
        # Adiciona estilo de conversa preferido
        context += f"Estilo de comunica√ß√£o preferido: {user_info['conversation_style']}\n"
        
        # Adiciona sentimento atual
        context += f"Sentimento atual: {user_info['session_data']['last_sentiment']}\n"
        
        # Adiciona √∫ltimas intera√ß√µes muito resumidas (apenas t√≥picos)
        if user_info["conversation_history"]:
            context += "Contexto recente: "
            recent_topics = []
            for interaction in user_info["conversation_history"][-3:]:
                if interaction.get("topics"):
                    recent_topics.extend(interaction["topics"])
            
            if recent_topics:
                context += f"recentemente falamos sobre {', '.join(set(recent_topics))}\n"
            
            # Adiciona √∫ltima pergunta do usu√°rio
            context += f"√öltima pergunta: {user_info['conversation_history'][-1]['user_message']}\n"
        
        return context
    
    def detect_intent_change(self, user_id, current_message):
        """Detecta se houve mudan√ßa significativa de inten√ß√£o ou t√≥pico."""
        user_info = self.get_user_info(user_id)
        
        if not user_info["conversation_history"]:
            return True  # Primeira mensagem sempre √© uma nova inten√ß√£o
        
        # Extraindo t√≥picos da mensagem atual
        current_topics = self.text_analyzer.extract_topics(current_message)
        
        # Obtendo t√≥picos da √∫ltima mensagem
        last_interaction = user_info["conversation_history"][-1]
        last_topics = last_interaction.get("topics", [])
        
        # Verificando sobreposi√ß√£o de t√≥picos
        common_topics = set(current_topics).intersection(set(last_topics))
        
        # Se n√£o houver t√≥picos em comum, prov√°vel mudan√ßa de inten√ß√£o
        if not common_topics and (current_topics or last_topics):
            return True
        
        # Verificando comprimento da mensagem
        # Mensagens muito curtas ap√≥s uma longa podem indicar mudan√ßa de contexto
        current_length = len(current_message.split())
        last_length = len(last_interaction["user_message"].split())
        
        if current_length <= 3 and last_length > 15:
            return True
        
        # Verificando palavras-chave de transi√ß√£o
        transition_keywords = ["outra", "diferente", "novo", "mudar", "outro assunto", "falando em"]
        if any(keyword in current_message.lower() for keyword in transition_keywords):
            return True
        
        return False

class MongoDBStorage:
    """Classe para gerenciar o armazenamento de dados no MongoDB."""
    
    def __init__(self):
        """Inicializa a conex√£o com o MongoDB."""
        self.client = None
        self.db = None
        self.users_collection = None
        self.mongodb_uri = os.getenv('MONGODB_URI')
        
        if self.mongodb_uri:
            try:
                logger.info("Conectando ao MongoDB...")
                self.client = MongoClient(self.mongodb_uri)
                self.db = self.client.finance_bot
                self.users_collection = self.db.users
                # Criando √≠ndice para melhorar a performance das consultas
                self.users_collection.create_index("user_id")
                logger.info("Conex√£o com MongoDB estabelecida com sucesso!")
            except Exception as e:
                logger.error(f"Erro ao conectar ao MongoDB: {str(e)}")
                logger.error(f"Traceback: {traceback.format_exc()}")
                self.client = None
        else:
            logger.info("URI do MongoDB n√£o configurada. Usando armazenamento local.")
    
    def is_connected(self):
        """Verifica se a conex√£o com o MongoDB est√° ativa."""
        return self.client is not None
    
    def get_user_info(self, user_id):
        """Obt√©m informa√ß√µes sobre um usu√°rio espec√≠fico."""
        user_id_str = str(user_id)
        
        if not self.is_connected():
            logger.warning("MongoDB n√£o est√° conectado. N√£o foi poss√≠vel obter informa√ß√µes do usu√°rio.")
            return None
        
        user_doc = self.users_collection.find_one({"user_id": user_id_str})
        
        if not user_doc:
            # Criando um novo documento para o usu√°rio
            user_doc = {
                "user_id": user_id_str,
                "first_interaction": datetime.now(),
                "last_interaction": datetime.now(),
                "interaction_count": 0,
                "topics": [],
                "preferences": {},
                "conversation_history": []
            }
            self.users_collection.insert_one(user_doc)
            logger.info(f"Novo usu√°rio criado no MongoDB: {user_id_str}")
        
        return user_doc
    
    def update_user_interaction(self, user_id, user_message, bot_response):
        """Atualiza as informa√ß√µes de intera√ß√£o de um usu√°rio."""
        if not self.is_connected():
            logger.warning("MongoDB n√£o est√° conectado. N√£o foi poss√≠vel atualizar intera√ß√£o do usu√°rio.")
            return
        
        user_id_str = str(user_id)
        
        # Obtendo o documento do usu√°rio
        user_doc = self.get_user_info(user_id)
        
        # Atualizando dados b√°sicos
        update_data = {
            "last_interaction": datetime.now(),
            "interaction_count": user_doc["interaction_count"] + 1
        }
        
        # Criando nova intera√ß√£o
        new_interaction = {
            "timestamp": datetime.now(),
            "user_message": user_message,
            "bot_response": bot_response
        }
        
        # Identificando t√≥picos com base em palavras-chave
        topics_keywords = {
            "investimentos": ["investir", "investimento", "a√ß√£o", "a√ß√µes", "bolsa"],
            "renda_fixa": ["renda fixa", "cdb", "tesouro", "lci", "lca"],
            "aposentadoria": ["aposentadoria", "previd√™ncia", "inss", "aposentar"],
            "d√≠vidas": ["d√≠vida", "d√≠vidas", "empr√©stimo", "cr√©dito", "financiamento"],
            "economia": ["economia", "poupar", "economizar", "gastos"],
            "educa√ß√£o_financeira": ["educa√ß√£o financeira", "aprender", "finan√ßas"],
            "impostos": ["imposto", "impostos", "ir", "declara√ß√£o"],
            "im√≥veis": ["im√≥vel", "im√≥veis", "casa", "apartamento", "financiamento"]
        }
        
        new_topics = []
        for topic, keywords in topics_keywords.items():
            for keyword in keywords:
                if keyword.lower() in user_message.lower() and topic not in user_doc["topics"]:
                    new_topics.append(topic)
        
        # Atualizando o documento do usu√°rio no MongoDB
        self.users_collection.update_one(
            {"user_id": user_id_str},
            {
                "$set": update_data,
                "$push": {
                    "conversation_history": {
                        "$each": [new_interaction],
                        "$slice": -10  # Mant√©m apenas as 10 √∫ltimas intera√ß√µes
                    },
                    "topics": {
                        "$each": new_topics
                    }
                }
            }
        )
        
        logger.debug(f"Intera√ß√£o do usu√°rio {user_id_str} atualizada no MongoDB")
    
    def get_conversation_summary(self, user_id):
        """Obt√©m um resumo das conversas recentes com o usu√°rio."""
        if not self.is_connected():
            logger.warning("MongoDB n√£o est√° conectado. N√£o foi poss√≠vel obter resumo da conversa.")
            return "N√£o foi poss√≠vel acessar o hist√≥rico de conversas."
        
        user_id_str = str(user_id)
        user_doc = self.get_user_info(user_id)
        
        if not user_doc or not user_doc.get("conversation_history"):
            return "N√£o h√° hist√≥rico de conversas anteriores."
        
        summary = "Resumo das conversas recentes:\n\n"
        
        # Pegando as 3 √∫ltimas intera√ß√µes
        recent_interactions = user_doc["conversation_history"][-3:]
        
        for i, interaction in enumerate(recent_interactions, 1):
            timestamp = interaction["timestamp"].strftime("%d/%m/%Y %H:%M") if isinstance(interaction["timestamp"], datetime) else "Data desconhecida"
            summary += f"Intera√ß√£o {i} ({timestamp}):\n"
            summary += f"Usu√°rio: {interaction['user_message']}\n"
            summary += f"Bot: {interaction['bot_response'][:100]}...\n\n"
        
        summary += f"T√≥picos de interesse: {', '.join(user_doc['topics']) if user_doc['topics'] else 'Nenhum identificado ainda'}\n"
        summary += f"Total de intera√ß√µes: {user_doc['interaction_count']}"
        
        return summary

class OpenAIAdvisor:
    def __init__(self):
        logger.info("Iniciando configura√ß√£o da API OpenAI...")
        try:
            if not OPENAI_API_KEY:
                raise ValueError("OPENAI_API_KEY n√£o encontrada nas vari√°veis de ambiente!")
            
            self.client = OpenAI(api_key=OPENAI_API_KEY)
            
            # Verificando se devemos usar MongoDB ou armazenamento local
            mongodb_uri = os.getenv('MONGODB_URI')
            if mongodb_uri:
                logger.info("Usando MongoDB para armazenamento de dados")
                self.storage = MongoDBStorage()
                # Verificando se a conex√£o foi bem-sucedida
                if not self.storage.is_connected():
                    logger.warning("Falha na conex√£o com MongoDB. Usando armazenamento local como fallback.")
                    self.storage = UserMemory()
            else:
                logger.info("Usando armazenamento local para dados dos usu√°rios")
                self.storage = UserMemory()
            
            # Inicializando o gerenciador de personalidades e analisador de texto
            self.personality_manager = PersonalityManager()
            self.text_analyzer = TextAnalyzer()
            
            # Inicializando cache para evitar chamadas repetidas
            self.response_cache = {}
            self.cache_expiry = 3600  # Cache v√°lido por 1 hora
                
            logger.info("Cliente OpenAI configurado com sucesso!")
        except Exception as e:
            logger.error(f"Erro ao configurar cliente OpenAI: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise
    
    def _get_current_date(self):
        """Retorna a data atual formatada."""
        return datetime.now().strftime("%d/%m/%Y")
    
    def _is_question_in_cache(self, user_id, question):
        """Verifica se uma pergunta semelhante est√° no cache."""
        if user_id not in self.response_cache:
            return None
        
        for cached_q, response_data in self.response_cache[user_id].items():
            # Verifica similaridade b√°sica
            if cached_q.lower() == question.lower():
                timestamp = response_data["timestamp"]
                # Verifica se o cache ainda √© v√°lido
                if (datetime.now() - timestamp).total_seconds() < self.cache_expiry:
                    return response_data["response"]
        
        return None
    
    def _add_to_cache(self, user_id, question, response):
        """Adiciona uma resposta ao cache."""
        if user_id not in self.response_cache:
            self.response_cache[user_id] = {}
        
        self.response_cache[user_id][question] = {
            "response": response,
            "timestamp": datetime.now()
        }
    
    def _clean_expired_cache(self):
        """Limpa entradas expiradas do cache."""
        for user_id in list(self.response_cache.keys()):
            for question in list(self.response_cache[user_id].keys()):
                timestamp = self.response_cache[user_id][question]["timestamp"]
                if (datetime.now() - timestamp).total_seconds() > self.cache_expiry:
                    del self.response_cache[user_id][question]
            
            # Remove usu√°rio do cache se n√£o tiver mais entradas
            if not self.response_cache[user_id]:
                del self.response_cache[user_id]

    async def generate_response(self, user_input: str, user_id: int, context_data=None, search_web=True):
        try:
            logger.debug(f"Gerando resposta para input: {user_input}")
            
            # Limpando cache expirado periodicamente
            self._clean_expired_cache()
            
            # Verificando cache para perguntas semelhantes
            cached_response = self._is_question_in_cache(user_id, user_input)
            if cached_response:
                logger.info("Resposta encontrada no cache")
                return cached_response
            
            # Obtendo informa√ß√µes do usu√°rio
            user_info = self.storage.get_user_info(user_id)
            
            # Analisando caracter√≠sticas da mensagem
            sentiment = self.text_analyzer.analyze_sentiment(user_input)
            user_region = self.text_analyzer.detect_user_region(user_input) or user_info.get("detected_region")
            question_complexity = self.text_analyzer.detect_question_complexity(user_input)
            
            # Analisando se houve mudan√ßa de t√≥pico
            intent_changed = False
            if hasattr(self.storage, 'detect_intent_change'):
                intent_changed = self.storage.detect_intent_change(user_id, user_input)
            
            # Selecionando personalidade apropriada
            personality_type = self.personality_manager.select_appropriate_personality(user_input, user_info)
            personality = self.personality_manager.get_personality(personality_type)
            
            # Ajustando n√≠vel de formalidade com base no sentimento e complexidade
            formality_level = 2  # Padr√£o √© moderado
            if sentiment in ["positivo", "muito_positivo"]:
                formality_level = 1  # Mais informal para sentimentos positivos
            elif sentiment in ["negativo", "muito_negativo"]:
                formality_level = 3  # Mais formal para sentimentos negativos
            
            if question_complexity == "complexo":
                formality_level += 1  # Mais formal para perguntas complexas
            elif question_complexity == "simples":
                formality_level -= 1  # Mais informal para perguntas simples
            
            # Ajustando para ficar entre 0 e 4
            formality_level = max(0, min(formality_level, 4))
            
            # Realizando pesquisa na web se necess√°rio
            web_search_results = ""
            if search_web and any(keyword in user_input.lower() for keyword in ["atual", "hoje", "recente", "not√≠cia", "mercado", "taxa", "cota√ß√£o", "pre√ßo", "infla√ß√£o", "selic", "d√≥lar", "euro", "bolsa"]):
                logger.info("Detectada necessidade de informa√ß√µes atualizadas. Realizando pesquisa web.")
                search_query = f"finan√ßas {user_input} brasil atual"
                results = await GoogleSearch.search_google(search_query)
                if results:
                    web_search_results = GoogleSearch.format_search_results(results)
            
            # Obtendo contexto de mem√≥ria de longo prazo
            long_term_context = ""
            if hasattr(self.storage, 'get_long_term_context'):
                long_term_context = self.storage.get_long_term_context(user_id)
            
            # Construindo o contexto da conversa (√∫ltimas intera√ß√µes para continuidade)
            conversation_context = ""
            if user_info:
                if isinstance(self.storage, MongoDBStorage):
                    # Para MongoDB
                    if user_info.get("interaction_count", 0) > 0 and user_info.get("conversation_history"):
                        last_interactions = user_info["conversation_history"][-2:] if intent_changed else user_info["conversation_history"][-3:]
                        if last_interactions:
                            conversation_context = "√öltimas conversas:\n"
                            for interaction in last_interactions:
                                conversation_context += f"Usu√°rio: {interaction['user_message']}\n"
                                conversation_context += f"Voc√™: {interaction['bot_response'][:100]}...\n\n"
            else:
                    # Para UserMemory
                    if user_info.get("interaction_count", 0) > 0 and user_info.get("conversation_history"):
                        last_interactions = user_info["conversation_history"][-2:] if intent_changed else user_info["conversation_history"][-3:]
                        if last_interactions:
                            conversation_context = "√öltimas conversas:\n"
                            for interaction in last_interactions:
                                conversation_context += f"Usu√°rio: {interaction['user_message']}\n"
                                conversation_context += f"Voc√™: {interaction['bot_response'][:100]}...\n\n"
            
            # Adicionando dados de contexto espec√≠ficos se fornecidos
            if context_data:
                conversation_context += f"\nContexto adicional: {context_data}\n\n"
            
            # Sistema de prompt para personalidades diferentes e respostas humanizadas
            system_prompt = f"""Voc√™ √© {personality['name']}, {personality['description']} com mais de 15 anos no mercado. Responda como um especialista conversando de forma {personality['tone']}.

            CONTEXTO DO USU√ÅRIO:
            {long_term_context}
            
            REGRAS DE ESTILO:
            1. PERSONALIDADE: {personality['description']}
            2. TOM: {personality['tone']} 
            3. FORMALIDADE: {self.personality_manager.formality_levels[formality_level]}
            4. EXPERTISE: {personality['expertise']}
            5. ESTILO CONVERSACIONAL: {personality['conversation_style']}
            
            REGRAS CR√çTICAS:
            1. ADAPTE A PROFUNDIDADE DA RESPOSTA:
               - Para perguntas simples: use 1-3 frases informativas e diretas
               - Para perguntas t√©cnicas: forne√ßa respostas mais detalhadas (at√© 5-8 frases)
               - Quando o usu√°rio pedir detalhes: seja abrangente e did√°tico
            
            2. LINGUAGEM NATURAL BRASILEIRA:
               - Use express√µes como "{', '.join(personality['speech_patterns'][:3])}" ocasionalmente
               - Quando apropriado, use "{', '.join(personality['casual_expressions'][:3])}"
               - Adapte seu vocabul√°rio ao n√≠vel de conhecimento do usu√°rio
            
            3. RESPOSTA AO SENTIMENTO:
               - Sentimento atual detectado: {sentiment}
               - Ajuste seu tom para corresponder adequadamente
            
            4. ESTRUTURA:
               - Comece com um cumprimento breve ou reconhecimento se apropriado
               - Desenvolva a resposta em um fluxo conversacional natural
               - Conclua de forma pr√°tica e √∫til
            
            5. AUTENTICIDADE:
               - Voc√™ √© um especialista real, n√£o um chatbot
               - Responda com autoridade e experi√™ncia pr√°tica
               - Admita quando n√£o souber algo
            
            {conversation_context}
            
            {web_search_results}
            
            Dada sua experi√™ncia, analise a pergunta e forne√ßa uma resposta humana adaptada ao contexto - seja concisa para perguntas simples ou detalhada para quest√µes complexas ou espec√≠ficas."""
            
            logger.debug("Enviando requisi√ß√£o para a API da OpenAI...")
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ],
                temperature=0.7,
                max_tokens=800,
                top_p=0.9
            )
            
            raw_response = response.choices[0].message.content
            logger.debug(f"Resposta bruta da OpenAI: {raw_response}")
            
            # Humanizando a resposta com o estilo da personalidade escolhida
            humanized_response = self.personality_manager.create_human_variation(
                raw_response,
                personality_type=personality_type,
                formality_level=formality_level,
                add_fillers=(formality_level <= 3)  # Adiciona fillers apenas em n√≠veis mais informais
            )
            
            # Adicionando express√µes regionais ocasionalmente se uma regi√£o foi detectada
            if user_region and random.random() < 0.3:
                regional_expressions = self.personality_manager.get_regional_expressions(user_region)
                if regional_expressions and random.random() < 0.5:  # 50% de chance
                    regional_expr = random.choice(regional_expressions)
                    sentences = humanized_response.split('. ')
                    if len(sentences) > 2:
                        # Inserindo express√£o regional em uma frase aleat√≥ria (n√£o a primeira nem a √∫ltima)
                        insert_pos = random.randint(1, len(sentences) - 2)
                        sentences[insert_pos] = f"{sentences[insert_pos][:-1]}, {regional_expr}"
                        humanized_response = '. '.join(sentences)

            # Formatando para Markdown
            formatted_response = humanized_response.replace('*', '\\*')
            formatted_response = formatted_response.replace('_', '\\_')
            formatted_response = formatted_response.replace('`', '\\`')
            
            # Atualizando a mem√≥ria do usu√°rio
            self.storage.update_user_interaction(user_id, user_input, formatted_response)
            
            # Adicionando ao cache
            self._add_to_cache(user_id, user_input, formatted_response)
            
            return formatted_response

        except Exception as e:
            logger.error(f"Erro na gera√ß√£o de resposta: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return "Ops! Tive um problema ao processar sua pergunta. Pode tentar novamente?"

class TelegramBot:
    def __init__(self):
        logger.info("Iniciando TelegramBot...")
        try:
            self.advisor = OpenAIAdvisor()
            self.app = None
            
            # Inicializando componentes de humaniza√ß√£o
            self.personality_manager = PersonalityManager()
            self.text_analyzer = TextAnalyzer()
            
            # Frases de espera profissionais e naturais
            self.typing_messages = [
                "Analisando sua quest√£o...",
                "Consultando os dados...",
                "Processando isso...",
                "Um momento, por favor...",
                "Elaborando uma resposta...",
                "Verificando as informa√ß√µes...",
                "Pensando na melhor estrat√©gia...",
                "Avaliando as op√ß√µes...",
                "Buscando as informa√ß√µes mais recentes...",
                "Deixa eu pensar aqui...",
                "Estou considerando os detalhes...",
                "Reunindo os dados relevantes...",
                "Fazendo os c√°lculos...",
                "Analisando o cen√°rio atual...",
                "Organizando as ideias..."
            ]
            
            # Varia√ß√µes de pensamento para diferentes personalidades
            self.thinking_variations = {
                "default": [
                    "Analisando isso...", 
                    "Considerando os fatores...", 
                    "Verificando os dados..."
                ],
                "technical": [
                    "Processando os indicadores...", 
                    "Analisando m√©tricas...", 
                    "Calculando as vari√°veis..."
                ],
                "friendly": [
                    "Deixa eu ver isso rapidinho...", 
                    "Hmm, pensando aqui...", 
                    "Pera√≠, vou te responder j√°..."
                ],
                "mentor": [
                    "Refletindo sobre sua quest√£o...", 
                    "Pensando na melhor abordagem...", 
                    "Buscando um exemplo adequado..."
                ]
            }
            
            # Frases de follow-up engajadoras
            self.follow_up_questions = [
                "Essa perspectiva faz sentido para voc√™?",
                "Isso esclareceu sua d√∫vida?",
                "Quer explorar mais algum aspecto desse tema?",
                "Posso detalhar melhor algum ponto espec√≠fico?",
                "Esse caminho parece adequado para seu objetivo?",
                "Consegui responder completamente sua pergunta?",
                "H√° algo mais que gostaria de saber sobre esse assunto?",
                "Isso atende ao que voc√™ estava procurando?",
                "Faz sentido para sua situa√ß√£o?",
                "Gostaria de exemplos pr√°ticos sobre isso?",
                "Quer que eu aborde algum outro aspecto?",
                "Tem alguma d√∫vida espec√≠fica sobre o que expliquei?",
                "Isso te ajuda a tomar uma decis√£o?"
            ]
            
            # Varia√ß√µes de follow-up para diferentes personalidades
            self.follow_up_variations = {
                "default": [
                    "Isso atende sua expectativa?", 
                    "Posso ajudar com algo mais?", 
                    "Ficou claro ou quer que eu detalhe?"
                ],
                "technical": [
                    "Gostaria de mais dados sobre isso?", 
                    "Quer que analise algum outro indicador?", 
                    "Precisa de informa√ß√µes mais espec√≠ficas?"
                ],
                "friendly": [
                    "E a√≠, faz sentido pra voc√™?", 
                    "T√° tranquilo ou quer saber mais?", 
                    "Ficou alguma d√∫vida?"
                ],
                "mentor": [
                    "Como isso se aplica ao seu caso?", 
                    "Consegue visualizar isso no seu contexto?", 
                    "Quer explorar mais esse conceito?"
                ]
            }
            
            # Feedback de recebimento de mensagem
            self.message_acknowledgments = [
                "üëç",
                "Entendi",
                "Certo",
                "Vamos l√°",
                "Ok",
                "Sim",
                "Claro",
                "Perfeito",
                "Compreendi",
                "Vou ver isso"
            ]
            
            # Padr√£o de comportamento humano para digita√ß√£o
            self.human_typing_speeds = {
                "lento": (70, 90),  # caracteres por minuto
                "m√©dio": (120, 180),
                "r√°pido": (200, 280)
            }
            
            # Configura√ß√µes para varia√ß√£o de comportamento
            self.variation_settings = {
                "acknowledge_message_chance": 0.15,  # chance de enviar reconhecimento
                "thinking_message_chance": 0.5,     # chance de enviar "pensando"
                "follow_up_chance": 0.3,           # chance de perguntar follow-up
                "typing_indicator_delay_range": (0.3, 1.2),  # atraso antes de mostrar digitando
                "response_delay_range": (0.5, 2.0)  # atraso adicional antes de responder
            }
            
            logger.info("TelegramBot iniciado com sucesso!")
        except Exception as e:
            logger.error(f"Erro ao iniciar TelegramBot: {str(e)}")
            raise

    async def start(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        try:
            user = update.effective_user
            logger.info(f"Novo usu√°rio iniciou o bot: {user.id}")
            
            # Verificando se √© um usu√°rio recorrente
            user_info = self.advisor.storage.get_user_info(user.id)
            is_returning_user = user_info.get("interaction_count", 0) > 0
            
            # Enviando "digitando..." com uma pausa natural
            await asyncio.sleep(random.uniform(0.3, 0.7))
            await update.message.chat.send_action(action="typing")
            
            # Calculando um tempo de digita√ß√£o realista para a mensagem de boas-vindas
            if is_returning_user:
                # Mensagem mais curta para usu√°rios recorrentes
                typing_time = random.uniform(1.5, 2.5)
            else:
                # Mensagem mais longa para novos usu√°rios
                typing_time = random.uniform(2.5, 3.5)
            
            await asyncio.sleep(typing_time)
            
            # Preparando o teclado de op√ß√µes
            keyboard = [
                [
                    InlineKeyboardButton("üìà Investimentos", callback_data='investments'),
                    InlineKeyboardButton("üí∞ Renda Fixa", callback_data='fixed_income'),
                    InlineKeyboardButton("üìä Renda Vari√°vel", callback_data='variable_income')
                ],
                [
                    InlineKeyboardButton("üè¶ Fundos", callback_data='funds'),
                    InlineKeyboardButton("üí≤ Cripto", callback_data='crypto'),
                    InlineKeyboardButton("üìù Planejamento", callback_data='planning')
                ],
                [
                    InlineKeyboardButton("üìâ An√°lise de Mercado", callback_data='market_analysis'),
                    InlineKeyboardButton("üì∞ Not√≠cias", callback_data='news')
                ],
                [
                    InlineKeyboardButton("üîç Pesquisar na Web", callback_data='web_search'),
                    InlineKeyboardButton("‚ùì Ajuda", callback_data='help')
                ]
            ]
            
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            # Preparando mensagem de boas-vindas personalizada
            if is_returning_user:
                # Calculando o tempo desde a √∫ltima intera√ß√£o
                last_interaction = datetime.fromisoformat(user_info["last_interaction"])
                now = datetime.now()
                days_since_last = (now - last_interaction).days
                
                # Personalizando sauda√ß√£o com base no tempo passado
                if days_since_last == 0:
                    # Mesmo dia
                    greeting = f"Ol√° novamente, {user.first_name}! üëã Que bom te ver de volta t√£o r√°pido."
                elif days_since_last == 1:
                    # Dia seguinte
                    greeting = f"Ol√°, {user.first_name}! üëã Bom te ver novamente depois de ontem."
                elif days_since_last < 7:
                    # Menos de uma semana
                    greeting = f"Ol√°, {user.first_name}! üëã Bom te ver de volta depois de alguns dias."
                elif days_since_last < 30:
                    # Menos de um m√™s
                    greeting = f"Que bom te ver novamente, {user.first_name}! üëã Faz algumas semanas desde nossa √∫ltima conversa."
                else:
                    # Muito tempo
                    greeting = f"Nossa, {user.first_name}! üëã Quanto tempo! Que bom que voc√™ voltou."
                
                # Adicionando refer√™ncia a t√≥picos anteriores se existirem
                if user_info.get("topics"):
                    topics = user_info["topics"][:2]  # Pegando at√© 2 t√≥picos
                    topics_text = ", ".join(topics)
                    welcome_message = (
                        f"{greeting}\n\n"
                        f"Da √∫ltima vez conversamos sobre {topics_text}. Como posso te ajudar hoje? "
                        f"Escolha uma das op√ß√µes abaixo ou me fa√ßa uma pergunta direta."
                    )
                else:
                    welcome_message = (
                        f"{greeting}\n\n"
                        f"Como posso te ajudar hoje? Escolha uma das op√ß√µes abaixo ou me fa√ßa uma pergunta direta."
                    )
            else:
                # Novo usu√°rio - mensagem padr√£o
                welcome_message = (
                    f"Ol√°, {user.first_name}! üëã\n\n"
                    "Sou Paulo, consultor financeiro com mais de 15 anos de experi√™ncia no mercado. "
                    "Estou aqui para ajudar com suas d√∫vidas sobre investimentos, planejamento financeiro e economia.\n\n"
                    "Como posso auxiliar voc√™ hoje? Escolha uma op√ß√£o abaixo ou me fa√ßa uma pergunta direta sobre qualquer tema financeiro."
                )
            if not is_returning_user and random.random() < 0.7:
                await update.message.chat.send_action(action="typing")
                await asyncio.sleep(random.uniform(1.2, 2.0))
                
                follow_up_tips = (
                    "üí° Dica: Voc√™ pode me perguntar sobre praticamente qualquer assunto financeiro, como:\n\n"
                    "‚Ä¢ \"Qual a melhor forma de come√ßar a investir?\"\n"
                    "‚Ä¢ \"Como montar uma reserva de emerg√™ncia?\"\n"
                    "‚Ä¢ \"O que √© melhor: Tesouro Direto ou CDB?\"\n"
                    "‚Ä¢ \"Como funciona o mercado de a√ß√µes?\""
                )
                
                await update.message.reply_text(follow_up_tips)
            
            return WAITING_RESPONSE
            
        except Exception as e:
            logger.error(f"Erro no comando start: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            await update.message.reply_text(
                "Ops! Tive um problema ao iniciar. Pode tentar novamente?"
            )
            return ConversationHandler.END

    async def handle_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        try:
            user = update.effective_user
            message = update.message.text
            logger.info(f"Mensagem recebida do usu√°rio {user.id}: {message}")

            # Verificando se estamos aguardando uma consulta de pesquisa
            if context.user_data.get('awaiting_search_query'):
                return await self.handle_web_search(update, context)
            
            # Detectando a personalidade apropriada com base na mensagem
            personality_type = self.personality_manager.select_appropriate_personality(message)
            
            # Detectando sentimento da mensagem
            sentiment = self.text_analyzer.analyze_sentiment(message)
            
            # Calculando probabilidade de enviar reconhecimento com base no sentimento
            acknowledge_chance = self.variation_settings["acknowledge_message_chance"]
            if sentiment in ["positivo", "muito_positivo"]:
                acknowledge_chance += 0.1  # Aumenta chances para mensagens positivas
            elif len(message) < 10:
                acknowledge_chance += 0.15  # Aumenta chances para mensagens curtas
            
            # Enviando reconhecimento de recebimento ocasionalmente
            if random.random() < acknowledge_chance:
                # Escolhendo um reconhecimento apropriado com base no sentimento
                if sentiment in ["positivo", "muito_positivo"]:
                    ack_options = ["üëç", "Beleza", "Certo", "Sim"] 
                elif sentiment in ["negativo", "muito_negativo"]:
                    ack_options = ["Entendi", "Compreendo", "Ok"]
                else:
                    ack_options = self.message_acknowledgments
                
                await update.message.reply_text(random.choice(ack_options))
                
                # Adicionando uma pausa natural ap√≥s o reconhecimento
                await asyncio.sleep(random.uniform(0.5, 1.2))
            
            # Pausa breve e realista antes de mostrar o indicador de "digitando"
            await asyncio.sleep(random.uniform(*self.variation_settings["typing_indicator_delay_range"]))
            
            # Enviando mensagem de "pensando" ocasionalmente (apenas 50% das vezes)
            thinking_message = None
            if random.random() < self.variation_settings["thinking_message_chance"]:
                # Usando varia√ß√µes de pensamento baseadas na personalidade
                thinking_messages = self.thinking_variations.get(
                    personality_type, self.thinking_variations["default"]
                )
                thinking_text = random.choice(thinking_messages) if thinking_messages else random.choice(self.typing_messages)
                thinking_message = await update.message.reply_text(thinking_text)

            # Enviando mensagem de "digitando..."
            await update.message.chat.send_action(action="typing")
            
            # Analisando complexidade da pergunta
            question_complexity = self.text_analyzer.detect_question_complexity(message)
            
            # Calculando tempo de digita√ß√£o realista baseado na complexidade
            # 1. Primeiro, determinamos a "velocidade de digita√ß√£o" desta personalidade
            if personality_type == "technical":
                typing_speed_range = self.human_typing_speeds["r√°pido"]  # Especialistas t√©cnicos digitam mais r√°pido
            elif personality_type == "friendly":
                typing_speed_range = self.human_typing_speeds["m√©dio"]  # Pessoas amig√°veis digitam em velocidade m√©dia
            else:
                typing_speed_range = random.choice([
                    self.human_typing_speeds["m√©dio"], 
                    self.human_typing_speeds["r√°pido"]
                ])  # Outras personalidades variam
            
            # 2. Estimando o tamanho da resposta com base na complexidade da pergunta
            if question_complexity == "complexo":
                estimated_response_length = random.randint(1000, 1500)  # Caracteres estimados
            elif question_complexity == "m√©dio":
                estimated_response_length = random.randint(400, 800)
            else:
                estimated_response_length = random.randint(100, 300)
            
            # 3. Calculando tempo de digita√ß√£o natural em segundos
            typing_speed = random.uniform(*typing_speed_range)  # Caracteres por minuto
            typing_time_minutes = estimated_response_length / typing_speed
            typing_time_seconds = typing_time_minutes * 60
            
            # 4. Adicionando variabilidade e limitando valores extremos
            typing_time_seconds = min(max(typing_time_seconds * random.uniform(0.7, 1.1), 1.5), 6.0)
            
            # Ajustando para perguntas que precisam de "reflex√£o"
            if "explique" in message.lower() or "detalhe" in message.lower() or "como" in message.lower():
                typing_time_seconds += random.uniform(0.5, 1.5)  # Tempo adicional para "pensar"
            
            # Aplicando o tempo de digita√ß√£o calculado
            await asyncio.sleep(typing_time_seconds)
            
            # Removendo a mensagem de "estou pensando" se existir
            if thinking_message:
                await thinking_message.delete()
            
            # Verificando se √© uma solicita√ß√£o de busca na web
            search_keywords = ["atual", "hoje", "recente", "not√≠cia", "mercado", "taxa", "cota√ß√£o", "pre√ßo", 
                             "infla√ß√£o", "selic", "d√≥lar", "euro", "bolsa", "tend√™ncia", "proje√ß√£o", "previs√£o"]
            
            # Verificando se √© uma solicita√ß√£o de busca na web
            search_web = any(keyword in message.lower() for keyword in search_keywords)
            
            # Ajustando o contexto baseado na complexidade da pergunta
            context_data = None
            if question_complexity == "complexo":
                context_data = "O usu√°rio est√° solicitando uma explica√ß√£o detalhada e abrangente. Forne√ßa uma resposta completa com exemplos pr√°ticos quando poss√≠vel."
            
            # Gerando resposta
            response = await self.advisor.generate_response(message, user.id, context_data=context_data, search_web=search_web)
            
            # Pequena pausa adicional para humanizar a resposta
            await asyncio.sleep(random.uniform(*self.variation_settings["response_delay_range"]))
            
            # Dividindo respostas longas para n√£o exceder limites do Telegram
            if len(response) > 4096:
                chunks = [response[i:i+4096] for i in range(0, len(response), 4096)]
                for i, chunk in enumerate(chunks):
                    await update.message.reply_text(chunk, parse_mode='Markdown')
                    
                    # Se n√£o for o √∫ltimo chunk, simular digita√ß√£o entre chunks
                    if i < len(chunks) - 1:
                        await asyncio.sleep(random.uniform(0.5, 1.2))  # Pausa natural entre chunks
                        await update.message.chat.send_action(action="typing")
                        await asyncio.sleep(random.uniform(0.8, 1.5))
            else:
                    await update.message.reply_text(response, parse_mode='Markdown')
            
            # Adicionando follow-up ocasionalmente com probabilidade adaptativa
            message_length = len(response)
            follow_up_chance = self.variation_settings["follow_up_chance"]
            
            # Aumentando a chance para respostas longas ou complexas
            if message_length > 500 or question_complexity == "complexo":
                follow_up_chance += 0.2
            
            # Diminuindo a chance para mensagens que parecem conclusivas
            if any(term in response.lower() for term in ["espero ter ajudado", "mais alguma d√∫vida", "qualquer d√∫vida"]):
                follow_up_chance -= 0.15
            
            # Aumentando chance para t√≥picos que geralmente precisam de acompanhamento
            topics = self.text_analyzer.extract_topics(message)
            if any(topic in ["investimentos", "planejamento", "aposentadoria"] for topic in topics):
                follow_up_chance += 0.1
            
            # Aplicando a probabilidade de follow-up
            if random.random() < follow_up_chance:
                # Pausa mais longa e natural antes do follow-up
                await asyncio.sleep(random.uniform(1.0, 2.0))
                await update.message.chat.send_action(action="typing")
                await asyncio.sleep(random.uniform(0.5, 1.0))
                
                # Selecionando follow-up apropriado para a personalidade e complexidade
                if question_complexity == "complexo":
                    detailed_followups = [
                        "Gostaria que eu explorasse algum desses pontos em mais detalhes?",
                        "Tem alguma parte espec√≠fica que voc√™ quer que eu aprofunde?",
                        "Isso atendeu ao n√≠vel de detalhe que voc√™ precisava?",
                        "Quer que eu d√™ exemplos pr√°ticos de algum desses pontos?"
                    ]
                    follow_up = random.choice(detailed_followups)
                else:
                    # Usando varia√ß√µes de follow-up baseadas na personalidade
                    follow_up_options = self.follow_up_variations.get(
                        personality_type, self.follow_up_variations["default"]
                    )
                    follow_up = random.choice(follow_up_options if follow_up_options else self.follow_up_questions)
                
                await update.message.reply_text(follow_up)
            
            return WAITING_RESPONSE

        except Exception as e:
            logger.error(f"Erro ao processar mensagem: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            await update.message.reply_text(
                "Ops! Tive um problema ao processar sua pergunta. Pode tentar novamente?"
            )
            return WAITING_RESPONSE

    async def button_callback(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        try:
            query = update.callback_query
            user = query.from_user
            logger.info(f"Callback recebido do usu√°rio {user.id}: {query.data}")

            await query.answer()
            
            # Tratamento especial para pesquisa na web
            if query.data == 'web_search':
                # Pausa natural antes de responder
                await asyncio.sleep(random.uniform(0.3, 0.7))
                await query.message.chat.send_action(action="typing")
                await asyncio.sleep(random.uniform(0.7, 1.2))
                
                web_search_prompts = [
                    "Sobre o que voc√™ quer pesquisar?",
                    "O que voc√™ gostaria de saber?",
                    "Qual assunto financeiro voc√™ quer que eu pesquise?",
                    "Pode me dizer o que voc√™ quer saber?"
                ]
                
                await query.message.reply_text(random.choice(web_search_prompts))
                context.user_data['awaiting_search_query'] = True
                return WAITING_RESPONSE
            
            # Enviando "digitando..." com uma pausa natural
            await asyncio.sleep(random.uniform(0.2, 0.5))
            await query.message.chat.send_action(action="typing")
            
            # Selecionando uma personalidade apropriada para o t√≥pico
            personality_type = "default"
            if query.data in ['variable_income', 'market_analysis', 'crypto']:
                personality_type = "technical"  # T√≥picos mais t√©cnicos
            elif query.data in ['planning', 'help']:
                personality_type = "mentor"     # T√≥picos de planejamento/educa√ß√£o
            elif query.data in ['investments']:
                personality_type = "friendly"   # T√≥picos para iniciantes
            
            # Obtendo a personalidade
            personality = self.personality_manager.get_personality(personality_type)
            
            # Escolhendo uma mensagem de "pensando" baseada na personalidade
            if random.random() < 0.4:  # 40% de chance
                thinking_messages = self.thinking_variations.get(
                    personality_type, self.thinking_variations["default"]
                )
                thinking_message = await query.message.reply_text(
                    random.choice(thinking_messages) if thinking_messages else random.choice(self.typing_messages)
                )
            else:
                thinking_message = None
            
            # Calculando tempo de digita√ß√£o baseado no t√≥pico e personalidade
            # T√≥picos mais complexos requerem "mais tempo para pensar"
            if query.data in ['variable_income', 'market_analysis', 'crypto', 'funds']:
                # T√≥picos complexos
                typing_time = random.uniform(2.5, 4.0)
            elif query.data in ['planning', 'fixed_income']:
                # T√≥picos m√©dios
                typing_time = random.uniform(1.8, 3.0)
            else:
                # T√≥picos simples
                typing_time = random.uniform(1.2, 2.2)
            
            await asyncio.sleep(typing_time)
            
            # Removendo mensagem de "pensando" se existir
            if thinking_message:
                await thinking_message.delete()

            prompts = {
                'investments': "Quais s√£o as principais op√ß√µes de investimento no Brasil hoje, considerando diferentes perfis de risco e objetivos financeiros? O que voc√™ recomenda para quem est√° come√ßando?",
                'fixed_income': "Detalhe as melhores op√ß√µes de renda fixa dispon√≠veis no Brasil atualmente, com seus rendimentos aproximados, tributa√ß√£o, riscos e para qual perfil de investidor cada uma √© mais adequada.",
                'variable_income': "Quais s√£o as melhores estrat√©gias para investir em renda vari√°vel no Brasil atualmente? Fale sobre a√ß√µes, FIIs, ETFs e BDRs, com dicas pr√°ticas para diferentes perfis de investidor.",
                'funds': "Explique os principais tipos de fundos de investimento dispon√≠veis no Brasil, suas caracter√≠sticas, vantagens e desvantagens. Como escolher o fundo mais adequado para cada objetivo?",
                'crypto': "Qual a melhor forma de investir em criptomoedas com seguran√ßa no Brasil? Quais s√£o as principais criptomoedas, exchanges confi√°veis e estrat√©gias recomendadas para diferentes perfis?",
                'planning': "Como elaborar um planejamento financeiro completo e eficiente? Quais s√£o as etapas essenciais, desde o or√ßamento pessoal at√© a aposentadoria?",
                'market_analysis': "Como est√° o cen√°rio macroecon√¥mico e o mercado financeiro brasileiro atualmente? Quais s√£o as perspectivas para os pr√≥ximos meses e como isso afeta as decis√µes de investimento?",
                'news': "Quais s√£o as principais not√≠cias econ√¥micas e financeiras recentes que podem impactar os investimentos no Brasil? Como os investidores devem se posicionar diante desses acontecimentos?",
                'help': "De que maneiras voc√™ pode me ajudar com planejamento financeiro, investimentos e educa√ß√£o financeira? Quais s√£o seus diferenciais como consultor?"
            }

            if query.data in prompts:
                # Para an√°lise de mercado e not√≠cias, sempre pesquisar na web
                search_web = query.data in ['market_analysis', 'news']
                
                # Para t√≥picos espec√≠ficos, solicitar respostas mais detalhadas
                detailed_topics = ['variable_income', 'funds', 'crypto', 'planning']
                context_data = None
                
                if query.data in detailed_topics:
                    context_data = "Este √© um t√≥pico complexo que exige uma explica√ß√£o detalhada. Forne√ßa uma resposta abrangente com pontos espec√≠ficos e exemplos pr√°ticos."
                
                # Gerando resposta com a personalidade adequada
                response = await self.advisor.generate_response(
                    prompts[query.data], 
                    user.id, 
                    context_data=context_data, 
                    search_web=search_web
                )
                
                # Se a resposta for muito longa, dividir
                if len(response) > 4096:
                    chunks = [response[i:i+4096] for i in range(0, len(response), 4096)]
                    for i, chunk in enumerate(chunks):
                        await query.message.reply_text(chunk, parse_mode='Markdown')
                        # Se n√£o for o √∫ltimo chunk, simular digita√ß√£o entre chunks
                        if i < len(chunks) - 1:
                            await asyncio.sleep(random.uniform(0.5, 0.8))
                            await query.message.chat.send_action(action="typing")
                            await asyncio.sleep(random.uniform(0.8, 1.2))
                else:
                    await query.message.reply_text(response, parse_mode='Markdown')
                
                # Adicionando follow-up ocasionalmente
                if random.random() < 0.25:  # 25% de chance
                    await asyncio.sleep(random.uniform(1.0, 1.5))
                    await query.message.chat.send_action(action="typing")
                    await asyncio.sleep(random.uniform(0.5, 0.8))
                    
                    follow_up_options = self.follow_up_variations.get(
                        personality_type, self.follow_up_variations["default"]
                    )
                    follow_up = random.choice(follow_up_options if follow_up_options else self.follow_up_questions)
                    
                    await query.message.reply_text(follow_up)
            else:
                logger.warning(f"Callback n√£o reconhecido: {query.data}")
                await query.message.reply_text("N√£o entendi essa op√ß√£o. Pode tentar novamente?")
            
            return WAITING_RESPONSE

        except Exception as e:
            logger.error(f"Erro no callback: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            await query.message.reply_text(
                "Ops! Tive um problema ao processar sua solicita√ß√£o. Pode tentar novamente?"
            )
            return WAITING_RESPONSE
    
    async def handle_web_search(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Trata consultas espec√≠ficas de pesquisa na web."""
        user = update.effective_user
        query = update.message.text
        
        # Verificando se estamos aguardando uma consulta de pesquisa
        if context.user_data.get('awaiting_search_query'):
            # Varia√ß√µes de mensagens para indicar que estamos pesquisando
            searching_messages = [
                "Pesquisando...",
                "Procurando informa√ß√µes...",
                "Buscando dados atualizados...",
                "Consultando fontes confi√°veis...",
                "Coletando informa√ß√µes recentes..."
            ]
            
            # Enviando mensagem de "pesquisando" ap√≥s uma pequena pausa
            await asyncio.sleep(random.uniform(0.3, 0.7))
            search_message = await update.message.reply_text(random.choice(searching_messages))
            
            # Enviando mensagem de "digitando..."
            await update.message.chat.send_action(action="typing")
            
            # Realizando a pesquisa
            search_query = f"finan√ßas {query} brasil atual"
            results = await GoogleSearch.search_google(search_query)
            
            # Simulando o tempo de pesquisa
            await asyncio.sleep(random.uniform(1.5, 3.0))
            
            # Removendo a mensagem de "pesquisando"
            await search_message.delete()
            
            # Enviando "digitando..." novamente para indicar que estamos processando os resultados
            await update.message.chat.send_action(action="typing")
            await asyncio.sleep(random.uniform(1.0, 2.0))
            
            if results:
                # Gerando resposta com base nos resultados da pesquisa
                context_data = GoogleSearch.format_search_results(results)
                
                # Usando uma personalidade mais t√©cnica para respostas baseadas em pesquisas
                response = await self.advisor.generate_response(
                    f"Com base nas informa√ß√µes recentes sobre '{query}'", 
                    user.id, 
                    context_data=context_data,
                    search_web=False  # J√° fizemos a pesquisa manualmente
                )
                
                # Dividindo respostas longas
                if len(response) > 4096:
                    chunks = [response[i:i+4096] for i in range(0, len(response), 4096)]
                    for i, chunk in enumerate(chunks):
                        await update.message.reply_text(chunk, parse_mode='Markdown')
                        # Se n√£o for o √∫ltimo chunk, simular digita√ß√£o entre chunks
                        if i < len(chunks) - 1:
                            await asyncio.sleep(random.uniform(0.5, 0.8))
                            await update.message.chat.send_action(action="typing")
                            await asyncio.sleep(random.uniform(0.8, 1.2))
                else:
                    await update.message.reply_text(response, parse_mode='Markdown')
                
                # Adicionando ocasionalmente uma pergunta sobre a utilidade da pesquisa
                if random.random() < 0.3:
                    utility_questions = [
                        "Essas informa√ß√µes foram √∫teis?",
                        "Isso responde √† sua pergunta?",
                        "Gostaria de saber mais algum detalhe espec√≠fico?",
                        "H√° algo espec√≠fico desses dados que voc√™ gostaria de entender melhor?"
                    ]
                    
                    await asyncio.sleep(random.uniform(1.0, 1.5))
                    await update.message.chat.send_action(action="typing")
                    await asyncio.sleep(random.uniform(0.5, 0.8))
                    
                    await update.message.reply_text(random.choice(utility_questions))
            else:
                no_results_responses = [
                    "N√£o encontrei informa√ß√µes espec√≠ficas sobre isso. Pode tentar reformular sua pergunta?",
                    "Parece que n√£o consegui encontrar dados confi√°veis sobre esse tema. Poderia detalhar melhor o que est√° procurando?",
                    "N√£o achei informa√ß√µes recentes sobre isso. Talvez possamos abordar o assunto de outra forma?",
                    "N√£o encontrei resultados satisfat√≥rios. Poderia tentar com outras palavras-chave?"
                ]
                
                await update.message.reply_text(random.choice(no_results_responses))
            
            # Resetando o estado de espera
            context.user_data['awaiting_search_query'] = False
            
        return WAITING_RESPONSE

    def run(self):
        try:
            logger.info("Iniciando aplica√ß√£o do bot...")
            self.app = Application.builder().token(TOKEN).build()
            
            # Importando asyncio aqui para evitar problemas de importa√ß√£o circular
            import asyncio
            global asyncio
            
            # Configurando o ConversationHandler
            conv_handler = ConversationHandler(
                entry_points=[CommandHandler("start", self.start)],
                states={
                    WAITING_RESPONSE: [
                        MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_message),
                        CallbackQueryHandler(self.button_callback)
                    ],
                    FOLLOW_UP: [
                        MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_message),
                        CallbackQueryHandler(self.button_callback)
                    ]
                },
                fallbacks=[CommandHandler("start", self.start)]
            )
            
            # Adicionando handlers
            self.app.add_handler(conv_handler)
            
            logger.info("Bot iniciado com sucesso! Iniciando polling...")
            self.app.run_polling(allowed_updates=Update.ALL_TYPES)
            
        except Exception as e:
            logger.error(f"Erro fatal ao iniciar o bot: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise

if __name__ == "__main__":
    try:
        # Verificar se o bot j√° est√° em execu√ß√£o
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        # Tenta vincular a uma porta espec√≠fica
        try:
            s.bind(('localhost', 12345))
        except socket.error:
            logger.critical("Outra inst√¢ncia do bot j√° est√° em execu√ß√£o!")
            sys.exit(1)
            
        if not TOKEN:
            raise ValueError("Token do Telegram n√£o encontrado no arquivo .env!")
        
        if not OPENAI_API_KEY:
            raise ValueError("API Key da OpenAI n√£o encontrada no arquivo .env!")
        
        # Inicializando modelos de NLP necess√°rios
        def init_models():
            """Inicializa e baixa os modelos necess√°rios para NLP"""
            try:
                logger.info("Verificando e baixando recursos NLTK necess√°rios...")
                try:
                    nltk.data.find('vader_lexicon')
                    logger.info("Recursos NLTK j√° est√£o dispon√≠veis")
                except LookupError:
                    logger.info("Baixando vader_lexicon para an√°lise de sentimento...")
                    nltk.download('vader_lexicon', quiet=True)
                
                logger.info("Verificando modelo spaCy...")
                try:
                    if not spacy.util.is_package("pt_core_news_sm"):
                        logger.info("Modelo spaCy em portugu√™s n√£o encontrado. Tentando baixar...")
                        os.system("python -m spacy download pt_core_news_sm")
                    else:
                        logger.info("Modelo spaCy em portugu√™s j√° est√° dispon√≠vel")
                except Exception as e:
                    logger.warning(f"N√£o foi poss√≠vel verificar ou baixar o modelo spaCy: {str(e)}")
                    logger.info("Tentando usar modelo em ingl√™s como fallback")
                    try:
                        if not spacy.util.is_package("en_core_web_sm"):
                            logger.info("Modelo spaCy em ingl√™s n√£o encontrado. Tentando baixar...")
                            os.system("python -m spacy download en_core_web_sm")
                    except Exception as e:
                        logger.error(f"N√£o foi poss√≠vel baixar nenhum modelo spaCy: {str(e)}")
                        logger.warning("Algumas funcionalidades de NLP estar√£o limitadas")
                
                logger.info("Inicializa√ß√£o de modelos NLP conclu√≠da")
            except Exception as e:
                logger.error(f"Erro ao inicializar modelos NLP: {str(e)}")
                logger.warning("O bot funcionar√° com capacidades de NLP limitadas")
        
        # Inicializando modelos NLP
        init_models()
        
        logger.info("Iniciando bot...")
        bot = TelegramBot()
        bot.run()
        
    except Exception as e:
        logger.critical(f"Erro cr√≠tico: {str(e)}")
        logger.critical(f"Traceback: {traceback.format_exc()}")
        sys.exit(1) 